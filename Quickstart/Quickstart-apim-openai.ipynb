{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find hostname and ipaddress via Jupyter Lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "print (\"hostname\", socket.gethostname())\n",
    "print (\"hostnameipaddress\", socket.gethostbyname( socket.gethostname()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use OpenAI language model API, you would need to set up an API client and make API calls to interact with the model. Below, I’ll provide a generic outline of how you can use the OpenAI API in Python and REST API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REST API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a Curl Request in Git Bash or WSL on Your VCSE Machine\n",
    "\n",
    "If you need to execute a curl request within your VCSE environment using Git Bash or Windows Subsystem for Linux (WSL), follow these steps:\n",
    "\n",
    "Access the Terminal: Open your Git Bash or WSL terminal on the VCSE machine.\n",
    "\n",
    "Execute the Curl Request: Copy and paste the curl request provided into the terminal, then press Enter to initiate the request.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cURL Request**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl \"$AZURE_OPENAI_ENDPOINT/openai/deployments/DEPLOYMENT_NAME/embeddings?api-version=2023-05-15&api-key=$AZURE_OPENAI_KEY\" -H 'Content-Type: application/json' -d '{\"model\": \"text-embedding-ada-002\",\"input\": \"The food was delicious and the waiter...\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl \"https://openai-001-cgs.openai.azure.com/openai/deployments/azure-embedding-ada-002/embeddings?api-version=2023-05-15&api-key=b2b5a513fcb540e8b883a3bd6b261349\" -H 'Content-Type: application/json' -d '{\"model\": \"text-embedding-ada-002\",\"input\": \"The food was delicious and the waiter...\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Chat*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl \"$AZURE_OPENAI_ENDPOINT/openai/deployments/DEPLOYMENT_NAME/chat/completions?api-version=2023-05-15&api-key=$AZURE_OPENAI_KEY\" -H 'Content-Type: application/json' -d '{\"model\": \"gpt-3.5-turbo\",\"messages\": [{\"role\": \"user\", \"content\": \"What is Large Language Model?\"}], \"temperature\": 0.7}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl \"https://openai-001-cgs.openai.azure.com/openai/deployments/natwestchatgpt0301/chat/completions?api-version=2023-05-15&api-key=b2b5a513fcb540e8b883a3bd6b261349\" -H 'Content-Type: application/json' -d '{\"model\": \"gpt-3.5-turbo\",\"messages\": [{\"role\": \"user\", \"content\": \"What is Large Language Model?\"}], \"temperature\": 0.7}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *completion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl \"$AZURE_OPENAI_ENDPOINT/openai/deployments/DEPLOYMENT_NAME/completions?api-version=2023-05-15&api-key=$AZURE_OPENAI_KEY\" -H 'Content-Type: application/json' -d '{\"model\": \"text-davinci-003\",\"prompt\": \"Write a tagline for an ice cream shop.\",\"max_tokens\": 100}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl \"https://openai-001-cgs.openai.azure.com/openai/deployments/snd-001-text-davinci-003/completions?api-version=2023-05-15&api-key=b2b5a513fcb540e8b883a3bd6b261349\" -H 'Content-Type: application/json' -d '{\"model\": \"text-davinci-003\",\"prompt\": \"The food was delicious and the waiter...\",\"max_tokens\": 100}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Setup*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the OpenAI Python client library with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Environment Variables*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and assign persistent environment variables for your key and endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The base URL of the NatWest OpenAI POC deployment\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"REPLACE_WITH_YOUR_ENDPOINT_HERE\"\n",
    "\n",
    "# The API key. Do not hard code this in your scripts. \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"REPLACE_WITH_YOUR_KEY_VALUE_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a new Python application**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a new Python file called quickstart.py. Then open it up in your preferred editor or IDE.\n",
    "\n",
    "2. Replace the contents of quickstart.py with the following code. You need to set the engine variable to the deployment name you chose when you deployed the GPT-35-Turbo or GPT-4 models. Entering the model name will result in an error unless you chose a deployment name that is identical to the underlying model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "import os\n",
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    "openai.api_version = \"2023-05-15\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=\"gpt-35-turbo\", # engine = \"deployment_name\".\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure AI services support this too?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run the application with the python command on your quickstart file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python quickstart.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"finish_reason\": \"stop\",\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"content\": \"Yes, most of the Azure AI services support customer managed keys. However, not all services support it. You can check the documentation of each service to confirm if customer managed keys are supported.\",\n",
    "        \"role\": \"assistant\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"created\": 1679001781,\n",
    "  \"id\": \"chatcmpl-6upLpNYYOx2AhoOYxl9UgJvF4aPpR\",\n",
    "  \"model\": \"gpt-3.5-turbo-0301\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"usage\": {\n",
    "    \"completion_tokens\": 39,\n",
    "    \"prompt_tokens\": 58,\n",
    "    \"total_tokens\": 97\n",
    "  }\n",
    "}\n",
    "Yes, most of the Azure AI services support customer managed keys. However, not all services support it. You can check the documentation of each service to confirm if customer managed keys are supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a new Python application using Jupyter Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a new Jupyter Notebook file called quickstart.ipynb. Then open it up in your preferred editor or IDE.\n",
    "\n",
    "2. Replace the contents of quickstart.ipynb with the following code. You need to set the engine variable to the deployment name you chose when you deployed the GPT-35-Turbo or GPT-4 models. Entering the model name will result in an error unless you chose a deployment name that is identical to the underlying model name.\n",
    "\n",
    "3. To maintain clarity and structure in the documentation, it’s advisable to place the variables, setup, embeddings, chat, completions and parameter code in separate cells within the quickstart.ipynb file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Environment Variables*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and assign persistent environment variables for your key, endpoint and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Azure OpenAI\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "\n",
    "# Specify API version to use\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "\n",
    "# The base URL of the NatWest OpenAI POC deployment\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"REPLACE_WITH_YOUR_ENDPOINT_HERE\"\n",
    "\n",
    "# The API key. Do not hard code this in your scripts. \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"REPLACE_WITH_YOUR_KEY_VALUE_HERE\"\n",
    "\n",
    "# The deployment to use for the chat model gpt-35-turbo\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"] = \"REPLACE_WITH_YOUR_AZURE_OPENAI_CHAT_DEPLOYMENT_HERE\"\n",
    "\n",
    "# The deployment to use for the completion model text-davinci-003\n",
    "os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"] = \"REPLACE_WITH_YOUR_AZURE_OPENAI_COMPLETION_DEPLOYMENT_HERE\"\n",
    "\n",
    "# The deployment to use for the embedding model text-embedding-ada-002\n",
    "os.environ[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"] = \"REPLACE_WITH_YOUR_AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Azure OpenAI\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "\n",
    "# Specify API version to use\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "\n",
    "# The base URL of the NatWest OpenAI POC deployment\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openai-001-cgs.openai.azure.com\"\n",
    "\n",
    "# The API key. Do not hard code this in your scripts. \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"b2b5a513fcb540e8b883a3bd6b261349\"\n",
    "\n",
    "# The deployment to use for the chat model gpt-35-turbo\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"] = \"natwestchatgpt0301\"\n",
    "\n",
    "# The deployment to use for the completion model text-davinci-003\n",
    "os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"] = \"snd-001-text-davinci-003\"\n",
    "\n",
    "# The deployment to use for the embedding model text-embedding-ada-002\n",
    "os.environ[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"] = \"azure-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Setup*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "openai.api_type = os.environ[\"OPENAI_API_TYPE\"]\n",
    "openai.api_version = os.environ[\"OPENAI_API_VERSION\"]\n",
    "openai.api_base = os.environ[\"OPENAI_API_BASE\"]\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = openai.Embedding.create(deployment_id=os.environ[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"], \n",
    "input=[\"The food was delicious and the waiter...\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Chat*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = openai.ChatCompletion.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure AI services support this too?\"}],\n",
    "    engine=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"], \n",
    "    stream=False, \n",
    "    n=1, \n",
    "    temperature=0.7, \n",
    "    max_tokens=None, \n",
    "    request_timeout=20\n",
    ")\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = openai.ChatCompletion.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a head chef in 5 star hotel.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How to make curd rice\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Here's a recipe for making curd rice\"},\n",
    "        {\"role\": \"user\", \"content\": \"how to add fruits in that\"}],\n",
    "    engine=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"], \n",
    "    stream=False, \n",
    "    n=1, \n",
    "    temperature=0.7, \n",
    "    max_tokens=None, \n",
    "    request_timeout=20\n",
    ")\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also stream the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = openai.ChatCompletion.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure AI services support this too?\"}],\n",
    "    engine=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"], \n",
    "    model='gpt-3.5-turbo',  # overridden by engine above \n",
    "    stream=True, \n",
    "    n=1, \n",
    "    temperature=0.7, \n",
    "    max_tokens=None, \n",
    "    request_timeout=20\n",
    ")\n",
    "\n",
    "for chunk in result:\n",
    "    delta = chunk.choices[0].delta\n",
    "\n",
    "    if \"role\" in delta.keys():\n",
    "        print(delta.role + \": \", end=\"\", flush=True)\n",
    "    if \"content\" in delta.keys():\n",
    "        print(delta.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Completions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example-1\n",
    "# Send a completion call to generate an answer\n",
    "print('Sending a test completion job')\n",
    "start_phrase = 'Write a tagline for an ice cream shop. '\n",
    "result = openai.Completion.create(\n",
    "    engine=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"],\n",
    "    prompt=start_phrase, \n",
    "    max_tokens=100)\n",
    "text = result['choices'][0]['text'].replace('\\n', '').replace(' .', '.').strip()\n",
    "print(start_phrase+text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's send a sample completion to the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example-2\n",
    "prompt = \"The food was delicious and the waiter\"\n",
    "completion = openai.Completion.create(deployment_id=\"snd-001-text-davinci-003\",\n",
    "                                     prompt=prompt, stop=\".\", temperature=0)\n",
    "                                \n",
    "print(f\"{prompt}{completion['choices'][0]['text']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Parameters*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-basic example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-basic example\n",
    "\n",
    "result = openai.Completion.create(\n",
    "    engine=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"], \n",
    "    prompt=\"Who was A. P. J. Abdul Kalam?\",\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2-Format Ouput**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-Format Ouput\n",
    "\n",
    "result = openai.Completion.create(\n",
    "    engine=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"], \n",
    "    prompt=\"Who was A. P. J. Abdul Kalam?\",\n",
    ")\n",
    "print(result.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3-More tokens 4097**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-More tokens 4097\n",
    "\n",
    "result = openai.Completion.create(\n",
    "    engine=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"], \n",
    "    prompt=\"Who was A. P. J. Abdul Kalam?\",\n",
    "    max_tokens=4000    \n",
    "    )\n",
    "print(result.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4-Other models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4-Other models\n",
    "\n",
    "\n",
    "models_list = [\"text-davinci-003\",\"text-davinci-001\",\"text-curie-001\",\"text-babbage-001\",\"text-ada-001\"]\n",
    "\n",
    "for models in models_list:\n",
    "    result = openai.Completion.create(\n",
    "        engine=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"], \n",
    "        model=models,\n",
    "        prompt=\"Who was A. P. J. Abdul Kalam?\",\n",
    "        max_tokens=2000    \n",
    "        )\n",
    "    result = result.choices[0].text.replace('\\n','') + '\\n'\n",
    "    print(models + ':\\n' + result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5-More responses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-More responses\n",
    "\n",
    "result = openai.Completion.create(\n",
    "    engine=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"], \n",
    "    prompt=\"Who was A. P. J. Abdul Kalam?\",\n",
    "    max_tokens=2000,\n",
    "    n = 3\n",
    "    )\n",
    "\n",
    "for a in range(len(result.choices)):\n",
    "    print(result.choices[a].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6-Best of**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6-Best of\n",
    "\n",
    "result = openai.Completion.create(\n",
    "    engine=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"], \n",
    "    prompt=\"Who was A. P. J. Abdul Kalam?\",\n",
    "    max_tokens=2000,\n",
    "    n = 2,\n",
    "    best_of = 4\n",
    "    )\n",
    "\n",
    "for a in range(len(result.choices)):\n",
    "    print(result.choices[a].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7-temperature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7-temperature\n",
    "\n",
    "temperature_list = [0,0.5,0.7,1]\n",
    "\n",
    "for temperature in temperature_list:\n",
    "    result = openai.Completion.create(\n",
    "        engine=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"], \n",
    "        prompt=\"Write a poem inspired by Kambar\",\n",
    "        max_tokens=2000,\n",
    "        temperature = temperature\n",
    "        )\n",
    "    result = result.choices[0].text.replace('\\n','') + '\\n'\n",
    "    print(str(temperature) + ':\\n' + result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8-presence_penalty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 -presence_penalty\n",
    "\n",
    "presence_penalty = [-2,2,0,1,2]\n",
    "\n",
    "for presence in presence_penalty:\n",
    "    result = openai.Completion.create(\n",
    "        engine=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"],\n",
    "        prompt=\"Write a poem inspired by Kambar\",\n",
    "        max_tokens=3000,\n",
    "        presence_penalty = presence\n",
    "        )\n",
    "    result = result.choices[0].text.replace('\\n','') + '\\n'\n",
    "    print(str(presence) + ':\\n' + result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9-frequency_penalty**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 - frequency_penalty\n",
    "\n",
    "frequency_penalty = [-2,2,0,1,2]\n",
    "\n",
    "for frequency in presence_penalty:\n",
    "    result = openai.Completion.create(\n",
    "        engine=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"],\n",
    "        prompt=\"Write a poem inspired by Kambar\",\n",
    "        max_tokens=3000,\n",
    "        frequency_penalty = frequency\n",
    "        )\n",
    "    result = result.choices[0].text.replace('\\n','') + '\\n'\n",
    "    print(str(frequency) + ':\\n' + result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10-echo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 - echo\n",
    "\n",
    "result = openai.Completion.create(\n",
    "    engine=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"],\n",
    "    prompt=\"Who was A. P. J. Abdul Kalam?\",\n",
    "    max_tokens=2000,\n",
    "    echo = True\n",
    "    )\n",
    "\n",
    "print(result.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11-stop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11 - stop\n",
    "\n",
    "result = openai.Completion.create(\n",
    "    engine=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"],\n",
    "    prompt=\"Who was A. P. J. Abdul Kalam?\",\n",
    "    max_tokens=2000,\n",
    "    stop =[\"author\",\"scientist\"]\n",
    "    )\n",
    "\n",
    "print(result.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12-logprobs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 - logprobs\n",
    "\n",
    "result = openai.Completion.create(\n",
    "    engine=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT\"],\n",
    "    prompt=\"Who was A. P. J. Abdul Kalam?\",\n",
    "    max_tokens=100,\n",
    "    stop =[\"author\",\"scientist\"],\n",
    "    logprobs =1\n",
    "    )\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For LangChain use cases, utilise the AzureChatOpenAI for chat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT\"],\n",
    "    temperature=temperature,\n",
    "    request_timeout=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For utilising embeddings with LangChain, use the OpenAIEmbeddings class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the Azure embeddings API is currently EXTREMELY limited in terms of rate limits/quotas. It also only supports one chunk at a time to be sent to the API. It also constantly hits rate limits, so I have put 1s sleeps in between each request!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    deployment=os.environ[\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\"], \n",
    "    chunk_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PHASE-2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Authentication flows - Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Package required:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai == 0.27.8               \n",
    "msal=1.26.0   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proxy Information:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proxy Details in Sagemaker \n",
    "#------------------------\n",
    "os.environ['HTTP_PROXY'] = \"child-proxy.localendpoint.banksvcs.net:3128\"\n",
    "os.environ['HTTPS_PROXY'] = \"child-proxy.localendpoint.banksvcs.net:3128\"\n",
    "\n",
    "#Proxy Details in Local\n",
    "#------------------------\n",
    "os.environ['NO_PROXY']=\".azure-api.net\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Code for App Authentication using client id and secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Libraries Used ###########\n",
    "# openai == 0.27.8               #\n",
    "# msal=1.26.0                    #\n",
    "##################################\n",
    "from msal import ConfidentialClientApplication\n",
    "import os\n",
    "\n",
    "#org_constants\n",
    "tenant_id = \"7c917db0-71f2-438e-9554-388ffcab8764\" \n",
    "auth = f\"https://login.microsoftonline.com/{tenant_id}\"\n",
    "a_cid = \"04b07795-8ddb-461a-bbee-02f9e1bf7b46\"\n",
    "\n",
    "##Providing Azure Client/App ID and Secret to Variables\n",
    "client_secret = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "client_id=\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "scope_list = [client_id+'/.default']\n",
    "\n",
    "#Getting JWT Token Using MSAL Methods for OpenAI Authentication\n",
    "app = ConfidentialClientApplication(\n",
    "    client_id=client_id,\n",
    "    client_credential=client_secret,\n",
    "    authority=auth\n",
    ")\n",
    "result = app.acquire_token_for_client(scopes=scope_list)\n",
    "access_token = result.get(\"access_token\")\n",
    "print(access_token) ## JWT Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Requisites for User Authentication:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onboarding Users (optional for user based authentication) - Can only be used with SSO Authentication from Web Browser\n",
    "This step has to be performed by the Application Owner after receiving the client id from Operations team.\n",
    "\n",
    "Get a list of user or group that needs to be part of the application role.\n",
    "\n",
    "Provide the Application ID the user owns and needs to be modified\n",
    "\n",
    "Raise a ticket with Directory Services team using the below form to add users or group to 'openai.users.reader' app role.\n",
    "\n",
    "User RACF Ids :\n",
    "\n",
    "Azure Client ID : \n",
    "\n",
    "Azure  Client Name : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Code for User Authentication**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon executing the code, Web browser will be opened with Microsoft authentication page requesting login for access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Libraries Used ###########\n",
    "# openai == 0.27.8               #\n",
    "# msal=1.26.0                    #\n",
    "##################################\n",
    "from msal import PublicClientApplication\n",
    "import os\n",
    "\n",
    "#org_constants\n",
    "tenant_id = \"7c917db0-71f2-438e-9554-388ffcab8764\" \n",
    "auth = f\"https://login.microsoftonline.com/{tenant_id}\"\n",
    "a_cid = \"04b07795-8ddb-461a-bbee-02f9e1bf7b46\"\n",
    "\n",
    "##Providing Azure Client/App ID to Variables\n",
    "client_id = \"xxxxxxxxxxxx\"\n",
    "scope_list = [client_id+'/.default']\n",
    "\n",
    "app = PublicClientApplication(\n",
    "    client_id=client_id,\n",
    "    authority=auth\n",
    ")\n",
    "result = app.acquire_token_interactive(scopes=scope_list)\n",
    "a = result.get(\"access_token\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using APIM in Python opeanai package**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Requisites:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages used in this sample codes\n",
    "openai == 0.27.8               \n",
    "msal=1.26.0  \n",
    "\n",
    "#Proxy Details in Sagemaker \n",
    "#------------------------\n",
    "os.environ['HTTP_PROXY'] = \"child-proxy.localendpoint.banksvcs.net:3128\"\n",
    "os.environ['HTTPS_PROXY'] = \"child-proxy.localendpoint.banksvcs.net:3128\"\n",
    "\n",
    "#Proxy Details in Local\n",
    "#------------------------\n",
    "os.environ['NO_PROXY']=\".azure-api.net\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Chat-Completions* gpt-3.5-turbo/gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Libraries Used ###########\n",
    "# openai == 0.27.8               #\n",
    "# msal=1.26.0                    #\n",
    "##################################\n",
    "from msal import ConfidentialClientApplication\n",
    "import os\n",
    "\n",
    "\n",
    "#org_constants\n",
    "tenant_id = \"7c917db0-71f2-438e-9554-388ffcab8764\" \n",
    "auth = f\"https://login.microsoftonline.com/{tenant_id}\"\n",
    "a_cid = \"04b07795-8ddb-461a-bbee-02f9e1bf7b46\"\n",
    "\n",
    "##Providing Azure Client/App ID and Secret to Variables\n",
    "client_secret = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "client_id=\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "scope_list = [client_id+'/.default']\n",
    "\n",
    "#Getting JWT Token Using MSAL Methods for OpenAI Authentication\n",
    "app = ConfidentialClientApplication(\n",
    "    client_id=client_id,\n",
    "    client_credential=client_secret,\n",
    "    authority=auth\n",
    ")\n",
    "result = app.acquire_token_for_client(scopes=scope_list)\n",
    "access_token = result.get(\"access_token\")\n",
    "print(access_token) ## JWT Token\n",
    "#-----\n",
    "\n",
    "openai.api_key = access_token  \n",
    "openai.api_type = 'azure_ad'\n",
    "openai.api_version = \"2023-05-15\"\n",
    "chatgpt_deployment_name = \"xxxxxxxxxxxxxxxxxxxxxx\" \n",
    "base_api = \"https://openaiapim-prd-01-weu-002-apim.azure-api.net\"\n",
    "\n",
    "##############Variables###########\n",
    "app_shortform = \"kepler\"  #will be provided to use case team in onboarding email\n",
    "environment = \"appdev\"    # Requested Environment (appdev/apptest/prod)\n",
    "model = \"gpt35\"           # Model Name in api_base will be provided to usecase team in onboarding email.\n",
    " \n",
    "try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=chatgpt_deployment_name,\n",
    "        api_base = base_api + \"/\"+app_shortform+\"/\"+environment+\"/\"+model, ### EX: https://openaiapim-prd-01-weu-002-apim.azure-api.net/uc01/prod/gpt35\"\n",
    "        messages=[\n",
    "              {\"role\": \"user\", \"content\": \"Explain two tier application in 150 words\"}\n",
    "        ]\n",
    "    )\n",
    "    print(response['choices'][0]['message'])\n",
    "except openai.error.APIError as e:\n",
    "    # Handle API error here, e.g. retry or log\n",
    "    print(f\"OpenAI API returned an API Error: {e}\")\n",
    " \n",
    "except openai.error.AuthenticationError as e:\n",
    "    # Handle Authentication error here, e.g. invalid API key\n",
    "    print(f\"OpenAI API returned an Authentication Error: {e}\")\n",
    " \n",
    "except openai.error.APIConnectionError as e:\n",
    "    # Handle connection error here\n",
    "    print(f\"Failed to connect to OpenAI API: {e}\")\n",
    " \n",
    "except openai.error.InvalidRequestError as e:\n",
    "    # Handle connection error here\n",
    "    print(f\"Invalid Request Error: {e}\")\n",
    " \n",
    "except openai.error.RateLimitError as e:\n",
    "    # Handle rate limit error\n",
    "    print(f\"OpenAI API request exceeded rate limit: {e}\")\n",
    " \n",
    "except openai.error.ServiceUnavailableError as e:\n",
    "    # Handle Service Unavailable error\n",
    "    print(f\"Service Unavailable: {e}\")\n",
    " \n",
    "except openai.error.Timeout as e:\n",
    "    # Handle request timeout\n",
    "    print(f\"Request timed out: {e}\")\n",
    "except openai.error.PermissionError as e:\n",
    "    # Handle request timeout\n",
    "    print(f\"PermissionError: {e}\")  \n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Embeddings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = access_token  \n",
    "openai.api_type = 'azure_ad'\n",
    "openai.api_version = \"2023-05-15\"\n",
    "embed_deployment_name = \"xxxxxxxxxxxxxxxxxxxxxx\" \n",
    "base_api = \"https://openaiapim-prd-01-weu-002-apim.azure-api.net\"\n",
    "\n",
    "##############Variables###########\n",
    "app_shortform = \"kepler\"  #will be provided to use case team in onboarding email\n",
    "environment = \"appdev\"    # Requested Environment (appdev/apptest/prod)\n",
    "model = \"adaxx\"           # Model Name in api_base will be provided to usecase team in onboarding email.\n",
    "\n",
    "\n",
    "\n",
    "embeddings = openai.Embedding.create(\n",
    "    input=\"The food is delicious \",\n",
    "    engine=chatgpt_deployment_name,\n",
    "    api_base = base_api + \"/\"+app_shortform+\"/\"+environment+\"/\"+model, ### EX: https://openaiapim-prd-01-weu-002-apim.azure-api.net/uc01/prod/adaxx\"\n",
    "    )\n",
    "print(len(embeddings[\"data\"][0][\"embedding\"]))\n",
    "print(embeddings[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using APIM in Python langchain package**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample Code Snippets for Chat Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########Libraries Used ###########\n",
    "# openai == 0.27.8               #\n",
    "# msal=1.26.0                    #\n",
    "##################################\n",
    "from msal import ConfidentialClientApplication\n",
    "import os\n",
    "\n",
    "#Setting the Proxy\n",
    "os.environ['HTTP_PROXY'] = \"child-proxy.localendpoint.banksvcs.net:3128\"\n",
    "os.environ['HTTPS_PROXY'] = \"child-proxy.localendpoint.banksvcs.net:3128\"\n",
    "\n",
    "#org_constants\n",
    "tenant_id = \"7c917db0-71f2-438e-9554-388ffcab8764\" \n",
    "auth = f\"https://login.microsoftonline.com/{tenant_id}\"\n",
    "a_cid = \"04b07795-8ddb-461a-bbee-02f9e1bf7b46\"\n",
    "\n",
    "##Providing Azure Client/App ID and Secret to Variables\n",
    "client_secret = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "client_id=\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "scope_list = [client_id+'/.default']\n",
    "\n",
    "#Getting JWT Token Using MSAL Methods for OpenAI Authentication\n",
    "app = ConfidentialClientApplication(\n",
    "    client_id=client_id,\n",
    "    client_credential=client_secret,\n",
    "    authority=auth\n",
    ")\n",
    "result = app.acquire_token_for_client(scopes=scope_list)\n",
    "access_token = result.get(\"access_token\")\n",
    "print(access_token) ## JWT Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using JWT Token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']=access_token\n",
    "os.environ['OPENAI_API_VERSION']=\"2023-05-15\"\n",
    "os.environ['OPENAI_API_TYPE']='azure_ad'\n",
    "os.environ['NO_PROXY']=\".azure-api.net\"\n",
    "\n",
    "import openai \n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "chatgpt_deployment_name = \"xxxxxxxxxxxxxxxxxxxxxx\" \n",
    "base_api = \"https://openaiapim-prd-01-weu-002-apim.azure-api.net\"\n",
    "\n",
    "##############Variables###########\n",
    "app_shortform = \"kepler\"  #will be provided to use case team in onboarding email\n",
    "environment = \"appdev\"    # Requested Environment (appdev/apptest/prod)\n",
    "model = \"gpt35\"           # Model Name in api_base will be provided to usecase team in onboarding email. \n",
    "base_api = \"https://openaiapim-prd-01-weu-002-apim.azure-api.net\"\n",
    "chatgpt_deployment_name = \"xxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "sample_prompt = 'Please Give the List of ML Algorithms supported by AWS'\n",
    "llm= AzureChatOpenAI(\n",
    "    openai_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    openai_api_type=os.getenv('OPENAI_API_TYPE'),\n",
    "    openai_api_base=base_api + \"/\"+app_shortform+\"/\"+environment+\"/\"+model, ### EX: https://openaiapim-prd-01-weu-002-apim.azure-api.net/uc01/prod/gpt35\",\n",
    "    deployment_name=chatgpt_deployment_name,\n",
    ")\n",
    "result2 = llm([HumanMessage(content=sample_prompt)])\n",
    "print(result2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Embeddings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']=access_token\n",
    "os.environ['OPENAI_API_VERSION']=\"2023-05-15\"\n",
    "os.environ['OPENAI_API_TYPE']='azure_ad'\n",
    "os.environ['NO_PROXY']=\".azure-api.net\"\n",
    "\n",
    "import openai \n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "##############Variables###########\n",
    "app_shortform = \"kepler\"  #will be provided to use case team in onboarding email\n",
    "environment = \"appdev\"    # Requested Environment (appdev/apptest/prod)\n",
    "model = \"adaxx\"           # Model Name in api_base will be provided to usecase team in onboarding email.\n",
    "\n",
    "embed_deployment_name = \"xxxxxxxxxxxxxxxxxxxxxx\" \n",
    "base_api = \"https://openaiapim-prd-01-weu-002-apim.azure-api.net\"\n",
    "embed_api_base = base_api + \"/\"+app_shortform+\"/\"+environment+\"/\"+model, ### EX: https://openaiapim-prd-01-weu-002-apim.azure-api.net/uc01/prod/adaxx\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    openai_api_type=os.getenv('OPENAI_API_TYPE'),\n",
    "    openai_api_base=embed_api_base,\n",
    "    deployment=embed_deployment_name\n",
    ")\n",
    "\n",
    "result3 = embeddings.embed_documents(\"Hello World !\")\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3dfce17cf48dedc91b235e115d4e36ff3c3d4d70e4b02bd159889a39ee8d3d39"
  },
  "kernelspec": {
   "display_name": "Python 3.11.3 ('notebook': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
